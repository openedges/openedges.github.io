<!DOCTYPE html>
<html>
<head>
	<title>Enlight NPU :: Model Zoo</title>
	<style>
		html {
			font-family: tahoma;
			padding: 30px;
		}

		table {
			border-collapse: collapse;
		}

		th, td {
			text-align: center;
			padding: 10px
		}

		th {
			border-bottom: 1px solid #000;
		}

		td {
			border-bottom: 1px solid #d0d0d0;
		}

		li {
			padding: 5px;
		}

		a {
			color: #58a6ff;
			text-decoration: none;
		}

		a:hover {
			text-decoration: underline;
		}

		h2 {
			margin-top: 40px;
		}

		h3 {
			margin-top: 30px;
		}

		@media (prefers-color-scheme: dark) {
			html {
				color: #eee;
				background-color: #333;
			}

			th {
				border-bottom: 1px solid #ccc;
			}

			td {
				border-bottom: 1px solid #808080;
			}
		}

	</style>
</head>
<body>

<h1>Enlight NPU :: Model Zoo</h1>

<ul>
	<li><a href="#classification_networks">Classification Networks</a></li>
	<li><a href="#object_detection_networks">Object Detection Networks</a></li>
	<li><a href="#face_detection_networks">Face Detection Networks</a></li>
	<li><a href="#pose_estimation_networks">Pose Estimation Networks</a></li>
</ul>

<h2 id="classification_networks">Classification Networks</h2>
	
<h3>ImageNet Results</h3>

<div>
		
	<table width="1280">
	<thead>
		<tr>
			<th>Model Name</th>
			<th>Type</th>
			<th>Input Size</th>
			<th>Top1 Acc (FP32)</th>
			<th>Top5 Acc (FP32)</th>
			<th>Top1 Acc (INT8)</th>
			<th>Top5 Acc (INT8)</th>
			<th>Giga MAC</th>
			<th>FPS</th>
			<th>Preview</th>
			<th>Source</th>
		</tr>
	</thead> 
	<tr>
		<td>mobilenet_v2</td>
		<td>TFLITE</td>
		<td>224x224</td>
		<td>71.090</td>
		<td>90.272</td>
		<td>69.738</td>
		<td>89.482</td>
		<td>0.3</td>
		<td></td>
		<td></td>
		<td><a href="https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz">tensorflow models</a></td>
	</tr>
	<tr>
		<td>mobilenet_v2</td>
		<td>ONNX</td>
		<td>224x224</td>
		<td>71.190</td>
		<td>90.206</td>
		<td>68.966</td>
		<td>88.676</td>
		<td>0.3</td>
		<td></td>
		<td></td>
		<td><a href="https://github.com/pytorch/vision/tree/main/torchvision">torchvision</a></td>
	</tr>
	<tr>
		<td>mobilenet_v2</td>
		<td>ONNX</td>
		<td>224x224</td>
		<td>67.208</td>
		<td>87.740</td>
		<td>65.950</td>
		<td>86.590</td>
		<td>0.4</td>
		<td></td>
		<td></td>
		<td><a href="https://github.com/onnx/models/blob/master/vision/classification/mobilenet/model/mobilenetv2-7.onnx">onnx models</a></td>
	</tr>
	<tr>
		<td>mobilenet_v2_1.4</td>
		<td>TFLITE</td>
		<td>224x224</td>
		<td>74.184</td>
		<td>91.920</td>
		<td>74.180</td>
		<td>91.922</td>
		<td>0.6</td>
		<td></td>
		<td></td>
		<td><a href="https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.4_224.tgz">tensorflow models</a></td>
	</tr>
	<tr>
		<td>resnet18</td>
		<td>ONNX</td>
		<td>224x224</td>
		<td>68.918</td>
		<td>88.826</td>
		<td>67.002</td>
		<td>87.628</td>
		<td>1.8</td>
		<td></td>
		<td></td>
		<td><a href="https://github.com/pytorch/vision/tree/main/torchvision">torchvision</a></td>
	</tr>
	<tr>
		<td>resnet34</td>
		<td>ONNX</td>
		<td>224x224</td>
		<td>72.770</td>
		<td>90.966</td>
		<td>71.020</td>
		<td>90.024</td>
		<td>3.7</td>
		<td></td>
		<td></td>
		<td><a href="https://github.com/pytorch/vision/tree/main/torchvision">torchvision</a></td>
	</tr>
	<tr>
		<td>resnet50</td>
		<td>ONNX</td>
		<td>224x224</td>
		<td>75.590</td>
		<td>92.784</td>
		<td>74.216</td>
		<td>91.922</td>
		<td>4.1</td>
		<td></td>
		<td></td>
		<td><a href="https://github.com/pytorch/vision/tree/main/torchvision">torchvision</a></td>
	</tr>
	<tr>
		<td>efficientnet-b0*</td>
		<td>ONNX</td>
		<td>224x224</td>
		<td></td>
		<td></td>
		<td></td>
		<td></td>
		<td></td>
		<td></td>
		<td></td>
		<td>in-house</td>
	</tr>
	</table>
		
	<p>* No SE layer, MbConv5x5(repeat=1) is replaced by MbConv3x3(repeat=2), and ReLU6 activaion instead of Swish activation for EfficientNet</p>
</div>


<h2 id="object_detection_networks">Object Detection Networks</h2>
	
<h3>VOC2007 Results</h3> 
	
<div>
		
	<table width="1280">
		<thead>
			<tr>
				<th>Model Name</th>
				<th>Type</th>
				<th>Input Size</th>
				<th>mAP (FP32)</th>
				<th>mAP (INT8)</th>
				<th>Giga MAC</th>
				<th>FPS</th>
				<th>Preview</th>
				<th>Source</th>
			</tr>
		</thead> 
		<tr>
			<td rowspan="3">ssd_mobilenet_v2</td>
			<td rowspan="3">ONNX</td>
			<td>300x300</td>
			<td>70.7</td>
			<td>70.1</td>
			<td>0.7</td>
			<td></td>
			<td><a href="/viewer/?url=https://raw.githubusercontent.com/openedges/openedges.github.io/main/samples/ssdlite300.enlight">preview</a></td>
			<td rowspan="3">in-house</td>
		</tr>
		<tr>
			<td>320x320</td>
			<td></td>
			<td></td>
			<td>0.8</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<td>512x512</td>
			<td>74.8</td>
			<td>74.0</td>
			<td>1.9</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<td rowspan="3">ssd_mobilenet_v2 (focalloss)</td>
			<td rowspan="3">ONNX</td>
			<td>300x300</td>
			<td></td>
			<td></td>
			<td>0.7</td>
			<td></td>
			<td><a href="/viewer/?url=https://raw.githubusercontent.com/openedges/openedges.github.io/main/samples/ssdlite300.enlight">preview</a></td>
			<td rowspan="3">in-house</td>
		</tr>
		<tr>
			<td>320x320</td>
			<td></td>
			<td></td>
			<td>0.8</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<td>512x512</td>
			<td></td>
			<td></td>
			<td>1.9</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<td>YOLOv2-voc*</td>
			<td>DarkNet</td>
			<td>416x416</td>
			<td>75.5</td>
			<td>73.5</td>
			<td>14.7</td>
			<td></td>
			<td></td>
			<td>in-house</td>
		</tr>
		<tr>
			<td>YOLOv2-tiny-voc</td>
			<td>DarkNet</td>
			<td>416x416</td>
			<td>55.6</td>
			<td>54.6</td>
			<td>3.5</td>
			<td></td>
			<td></td>
			<td><a href="https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov2-tiny-voc.cfg">cfg</a>, <a href="https://pjreddie.com/media/files/yolov2-tiny-voc.weights">weights</a></td>
		</tr>
	</table>

	<p>* YOLOv2 is trained after replacing buggy reorg layer to reorg3d layer.</p>			
</div>
	
<h3>COCO2017 Results</h3>
	
<div>
		
	<table width="1280">
		<thead>
			<tr>
				<th>Model Name</th>
				<th>Type</th>
				<th>Input Size</th>
				<th>AP (FP32)</th>
				<th>AP (INT8)</th>
				<th>Giga MAC</th>
				<th>FPS</th>
				<th>Preview</th>
				<th>Source</th>
			</tr>
		</thead>
		<tr>
			<td>ssd_mobilenet_v2_320x320</td>
			<td>TFLITE</td>
			<td>320x320</td>
			<td>33.6@IoU=0.5<br />19.2@IoU=0.5:0.95</td>
			<td></td>
			<td></td>
			<td></td>
			<td></td>
			<td><a href="http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz">link</a></td>
		</tr> 
		<tr>
			<td>YOLOv2* </td>
			<td>DarkNet</td>
			<td>416x416</td>
			<td>54.8@IoU=0.5<br />28.2@IoU=0.5:0.95</td>
			<td>54.2@IoU=0.5<br />27.5@IoU=0.5:0.95</td>
			<td>31.5</td>
			<td></td>
			<td></td>
			<td>in-house</td>
		</tr>
		<tr>
			<td>YOLOv2-tiny</td>
			<td>DarkNet</td>
			<td>416x416</td>
			<td>25.9@IoU=0.5<br />10.0@IoU=0.5:0.95</td>
			<td>25.5@IoU=0.5<br />9.7@IoU=0.5:0.95</td>
			<td>2.7</td>
			<td></td>
			<td></td>
			<td><a href="https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov2-tiny.cfg">cfg</a>, <a href="https://pjreddie.com/media/files/yolov2-tiny.weights">weights</a></td>
		</tr>
		<tr>
			<td rowspan="3">YOLOv3</td>
			<td rowspan="3">DarkNet</td>
			<td>320x320</td>
			<td>62.7@IoU=0.5<br />34.6@IoU=0.5:0.95</td>
			<td>62.9@IoU=0.5<br />34.6@IoU=0.5:0.95</td>
			<td>19.5</td>
			<td></td>
			<td></td>
			<td rowspan="3"><a href="https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg">cfg</a>, <a href="https://pjreddie.com/media/files/yolov3.weights">weights</a></td>
		</tr>
		<tr>
			<td>416x416</td>
			<td>67.1@IoU=0.5<br />37.6@IoU=0.5:0.95</td>
			<td>67.7@IoU=0.5<br />37.9@IoU=0.5:0.95</td>
			<td>32.9</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<td>608x608</td>
			<td>68.0@IoU=0.5<br />38.3@IoU=0.5:0.95</td>
			<td>68.9@IoU=0.5<br />38.7@IoU=0.5:0.95</td>
			<td>70.3</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<td>YOLOv3-tiny</td>
			<td>DarkNet</td>
			<td>416x416</td>
			<td>20.0@IoU=0.5<br />9.3@IoU=0.5:0.95</td>
			<td>19.7@IoU=0.5<br />9.1@IoU=0.5:0.95</td>
			<td>2.5</td>
			<td></td>
			<td></td>
			<td><a href="https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg">cfg</a>, <a href="https://pjreddie.com/media/files/yolov3-tiny.weights">weights</a></td>
		</tr>
		<tr>
			<td>YOLOv3-spp</td>
			<td>DarkNet</td>
			<td>608x608</td>
			<td>69.9@IoU=0.5<br />42.0@IoU=0.5:0.95</td>
			<td>69.3@IoU=0.5<br />41.3@IoU=0.5:0.95</td>
			<td>70.7</td>
			<td></td>
			<td></td>
			<td><a href="https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-spp.cfg">cfg</a>, <a href="https://pjreddie.com/media/files/yolov3-spp.weights">weights</a></td>
		</tr>
		<tr>
			<td rowspan="4">YOLOv4</td>
			<td rowspan="4">DarkNet</td>
			<td>320x320</td>
			<td>62.5@IoU=0.5<br />39.7@IoU=0.5:0.95</td>
			<td>62.2@IoU=0.5<br />39.0@IoU=0.5:0.95</td>
			<td>17.8</td>
			<td></td>
			<td></td>
			<td rowspan="4"><a href="https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg">cfg</a>, <a href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights">weights</a></td>
		</tr>
		<tr>
			<td>416x416</td>
			<td>70.5@IoU=0.5<br />46.1@IoU=0.5:0.95</td>
			<td>70.2@IoU=0.5<br />45.3@IoU=0.5:0.95</td>
			<td>30.1</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<td>512x512</td>
			<td>73.6@IoU=0.5<br />48.8@IoU=0.5:0.95</td>
			<td>72.9@IoU=0.5<br />47.8@IoU=0.5:0.95</td>
			<td>45.5</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<td>608x608</td>
			<td>74.6@IoU=0.5<br />49.8@IoU=0.5:0.95</td>
			<td>74.3@IoU=0.5<br />48.5@IoU=0.5:0.95</td>
			<td>64.2</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<td rowspan="2">YOLOv4-csp</td>
			<td rowspan="2">DarkNet</td>
			<td>512x512</td>
			<td>64.2@IoU=0.5<br />45.2@IoU=0.5:0.95</td>
			<td>62.7@IoU=0.5<br />42.8@IoU=0.5:0.95</td>
			<td>38.5</td>
			<td></td>
			<td></td>
			<td rowspan="2"><a href="https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-csp.cfg">cfg</a>, <a href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp.weights">weights</a></td>
		</tr>
		<tr>
			<td>608x608</td>
			<td>65.4@IoU=0.5<br />46.2@IoU=0.5:0.95</td>
			<td>64.0@IoU=0.5<br />43.7@IoU=0.5:0.95</td>
			<td>45.7</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<td>YOLOv4-tiny </td>
			<td>DarkNet</td>
			<td>416x416</td>
			<td>41.4@IoU=0.5<br />21.4@IoU=0.5:0.95</td>
			<td>40.7@IoU=0.5<br />20.7@IoU=0.5:0.95</td>
			<td>3.5</td>
			<td></td>
			<td></td>
			<td><a href="https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg">cfg</a>, <a href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights">weights</a></td>
		</tr>
	</table>
</div>

<p>* YOLOv2 is trained after replacing buggy reorg layer to reorg3d layer.</p>
	
<h2 id="face_detection_networks">Face Detection Networks</h2>

<div>
		
	<table width="1280">
		<thead>
			<tr>
				<th>Model Name</th>
				<th>Type</th>
				<th>Input Size</th>
				<th>AP (FP32)</th>
				<th>AP (INT8)</th>
				<th>Giga MAC</th>
				<th>FPS</th>
				<th>Preview</th>
				<th>Source</th>
			</tr>
		</thead>
		<tr>
			<td>Blaze Face</td>
			<td>TFLITE*</td>
			<td></td>
			<td>-</td>
			<td>-</td>
			<td></td>
			<td></td>
			<td></td>
			<td><a href="https://github.com/google/mediapipe/tree/master/mediapipe/graphs/face_detection">link</a></td>
		</tr>
	</table>
</div>

<p>* TfLite model is converted from ProtoBuf model.</p>
	
<h2 id="pose_estimation_networks">Pose Estimation Networks</h2>
	
<div>
	<table width="1280">
		<thead>
			<tr>
				<th>Model Name</th>
				<th>Type</th>
				<th>Input Size</th>
				<th>AP (FP32)</th>
				<th>AP (INT8)</th>
				<th>Giga MAC</th>
				<th>FPS</th>
				<th>Preview</th>
				<th>Source</th>
			</tr>
		</thead>
		<tr>
			<td>YOLO-pose</td>
			<td>ONNX</td>
			<td>640x640</td>
			<td>-</td>
			<td>-</td>
			<td></td>
			<td></td>
			<td></td>
			<td><a href="https://github.com/TexasInstruments/edgeai-yolov5/tree/yolo-pose">link</a></td>
		</tr>
	</table>
</div>
	
<h2>References</h2>
<div>
	<ul>
		<li>
			Classification Networks
			<ul>
				<li><a href="https://arxiv.org/abs/1801.04381">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></li>
				<li><a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></li>
			</ul>
		</li>
		<li>
			Object Detection Networks
			<ul>
				<li><a href="https://arxiv.org/abs/1512.02325">SSD: Single Shot MultiBox Detector</a></li>
				<li><a href="https://arxiv.org/abs/1612.08242">YOLO9000: Better, Faster, Stronger</a></li>
				<li><a href="https://arxiv.org/abs/1804.02767">YOLOv3: An Incremental Improvement</a></li>
				<li><a href="https://arxiv.org/abs/2004.10934">YOLOv4: Optimal Speed and Accuracy of Object Detection</a></li>
				<li><a href="https://arxiv.org/abs/2107.08430">YOLOX: Exceeding YOLO Series in 2021</a></li>
				<li><a href="https://arxiv.org/abs/2207.02696">YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</a></li>
			</ul>
		</li>
		<li>
			Face Detection Networks
			<ul>
				<li><a href="https://arxiv.org/abs/1907.05047">BlazeFace: Sub-millisecond Neural Face Detection on Mobile GPUs</a></li>
			</ul>
		</li>
		<li>
			Pose Estimation Networks
			<ul>
				<li><a href="https://arxiv.org/abs/2204.06806">YOLO-Pose: Enhancing YOLO for Multi Person Estimation Using Object Keypoint Similarity Loss</a></li>
			</ul>
		</li>
	</ul>
</div>

</body>
</html>